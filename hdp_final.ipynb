{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee514a7-f4aa-43b8-873a-76800cea500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Analysis of Hyperdirect Pathway Connectivity and Beta Suppression\n",
    "in STN-DBS Treatment Response\n",
    "\n",
    "Required packages:\n",
    "pip install pandas numpy scipy statsmodels scikit-learn matplotlib seaborn\n",
    "pip install pingouin>=0.5.3  # For mediation analysis with BCa bootstrap\n",
    "pip install statsmodels>=0.14.0  # For mixed models and FDR correction\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pingouin as pg\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# ================== PART 1: MEDIATION ANALYSIS FUNCTIONS ==================\n",
    "\n",
    "def run_mediation_analysis_complete(data, predictor, mediator, outcome, covariate, n_bootstrap=5000):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"MEDIATION ANALYSIS - Baron and Kenny Framework with BCa Bootstrap\")\n",
    "    print(f\"Predictor: {predictor} → Mediator: {mediator} → Outcome: {outcome}\")\n",
    "    print(f\"Covariate: {covariate}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Use pingouin's mediation_analysis which implements Baron & Kenny with BCa bootstrap\n",
    "    # This matches our methodology exactly\n",
    "    try:\n",
    "        # FIXED: Set return_dist=False to avoid tuple unpacking issues\n",
    "        stats_df = pg.mediation_analysis(\n",
    "            data=data,\n",
    "            x=predictor,         # Independent variable (HDP connectivity)\n",
    "            m=mediator,          # Mediator (Beta suppression)\n",
    "            y=outcome,           # Dependent variable (UPDRS change)\n",
    "            covar=covariate,     # Covariate (Dosage)\n",
    "            n_boot=n_bootstrap,  # 5000 bootstrap samples as specified\n",
    "            seed=42,             # For reproducibility\n",
    "            return_dist=False\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error in mediation analysis: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Extract key statistics from the stats DataFrame\n",
    "    # Path a: predictor -> mediator (controlling for covariate)\n",
    "    # Row label is 'M ~ X' where M is mediator and X is predictor\n",
    "    path_a_row = f'{mediator} ~ {predictor}'\n",
    "    if path_a_row in stats_df.index:\n",
    "        path_a_coeff = stats_df.loc[path_a_row, 'coef']\n",
    "        path_a_se = stats_df.loc[path_a_row, 'se']\n",
    "        path_a_pval = stats_df.loc[path_a_row, 'pval']\n",
    "        path_a_ci = [stats_df.loc[path_a_row, 'CI[2.5%]'], stats_df.loc[path_a_row, 'CI[97.5%]']]\n",
    "    else:\n",
    "        # Fallback to first row which should be path a\n",
    "        path_a_coeff = stats_df.iloc[0]['coef']\n",
    "        path_a_se = stats_df.iloc[0]['se']\n",
    "        path_a_pval = stats_df.iloc[0]['pval']\n",
    "        path_a_ci = [stats_df.iloc[0]['CI[2.5%]'], stats_df.iloc[0]['CI[97.5%]']]\n",
    "    \n",
    "    print(f\"Path a ({predictor} → {mediator}, {covariate}):\")\n",
    "    print(f\"  Coefficient: {path_a_coeff:.4f} (SE: {path_a_se:.4f})\")\n",
    "    print(f\"  95% CI: [{path_a_ci[0]:.4f}, {path_a_ci[1]:.4f}]\")\n",
    "    print(f\"  p-value: {path_a_pval:.4f}\")\n",
    "    \n",
    "    # Path b: mediator -> outcome (controlling for predictor and covariate)\n",
    "    # Row label is 'Y ~ M' where Y is outcome and M is mediator\n",
    "    path_b_row = f'{outcome} ~ {mediator}'\n",
    "    if path_b_row in stats_df.index:\n",
    "        path_b_coeff = stats_df.loc[path_b_row, 'coef']\n",
    "        path_b_se = stats_df.loc[path_b_row, 'se']\n",
    "        path_b_pval = stats_df.loc[path_b_row, 'pval']\n",
    "        path_b_ci = [stats_df.loc[path_b_row, 'CI[2.5%]'], stats_df.loc[path_b_row, 'CI[97.5%]']]\n",
    "    else:\n",
    "        # Fallback to second row which should be path b\n",
    "        path_b_coeff = stats_df.iloc[1]['coef']\n",
    "        path_b_se = stats_df.iloc[1]['se']\n",
    "        path_b_pval = stats_df.iloc[1]['pval']\n",
    "        path_b_ci = [stats_df.iloc[1]['CI[2.5%]'], stats_df.iloc[1]['CI[97.5%]']]\n",
    "    \n",
    "    print(f\"\\nPath b ({mediator} → {outcome}, {predictor}, {covariate}):\")\n",
    "    print(f\"  Coefficient: {path_b_coeff:.4f} (SE: {path_b_se:.4f})\")\n",
    "    print(f\"  95% CI: [{path_b_ci[0]:.4f}, {path_b_ci[1]:.4f}]\")\n",
    "    print(f\"  p-value: {path_b_pval:.4f}\")\n",
    "    \n",
    "    # Path c': Direct effect (predictor -> outcome controlling for mediator and covariate)\n",
    "    # This is the ADE (Average Direct Effect)\n",
    "    # Row label is 'Direct'\n",
    "    if 'Direct' in stats_df.index:\n",
    "        path_c_prime_coeff = stats_df.loc['Direct', 'coef']\n",
    "        path_c_prime_se = stats_df.loc['Direct', 'se']\n",
    "        path_c_prime_pval = stats_df.loc['Direct', 'pval']\n",
    "        path_c_prime_ci = [stats_df.loc['Direct', 'CI[2.5%]'], stats_df.loc['Direct', 'CI[97.5%]']]\n",
    "    else:\n",
    "        # Fallback\n",
    "        path_c_prime_coeff = stats_df.iloc[3]['coef']\n",
    "        path_c_prime_se = stats_df.iloc[3]['se']\n",
    "        path_c_prime_pval = stats_df.iloc[3]['pval']\n",
    "        path_c_prime_ci = [stats_df.iloc[3]['CI[2.5%]'], stats_df.iloc[3]['CI[97.5%]']]\n",
    "    \n",
    "    print(f\"\\nPath c' - ADE (Average Direct Effect):\")\n",
    "    print(f\"  {predictor} → {outcome}, {mediator}, {covariate}\")\n",
    "    print(f\"  β = {path_c_prime_coeff:.4f} (SE: {path_c_prime_se:.4f})\")\n",
    "    print(f\"  95% CI: [{path_c_prime_ci[0]:.4f}, {path_c_prime_ci[1]:.4f}]\")\n",
    "    print(f\"  p-value (raw): {path_c_prime_pval:.4f}\")\n",
    "    \n",
    "    # ACME (Average Causal Mediation Effect) - this is the indirect effect (a × b)\n",
    "    # Row label is 'Indirect'\n",
    "    if 'Indirect' in stats_df.index:\n",
    "        acme_coeff = stats_df.loc['Indirect', 'coef']\n",
    "        acme_se = stats_df.loc['Indirect', 'se']\n",
    "        acme_pval = stats_df.loc['Indirect', 'pval']\n",
    "        acme_ci = [stats_df.loc['Indirect', 'CI[2.5%]'], stats_df.loc['Indirect', 'CI[97.5%]']]\n",
    "    else:\n",
    "        # Fallback\n",
    "        acme_coeff = stats_df.iloc[4]['coef']\n",
    "        acme_se = stats_df.iloc[4]['se']\n",
    "        acme_pval = stats_df.iloc[4]['pval']\n",
    "        acme_ci = [stats_df.iloc[4]['CI[2.5%]'], stats_df.iloc[4]['CI[97.5%]']]\n",
    "    \n",
    "    print(f\"\\nACME (Average Causal Mediation Effect) - Indirect Effect (a × b):\")\n",
    "    print(f\"  β = {acme_coeff:.4f} (SE: {acme_se:.4f})\")\n",
    "    print(f\"  95% BCa CI: [{acme_ci[0]:.4f}, {acme_ci[1]:.4f}]\")\n",
    "    print(f\"  p-value (raw): {acme_pval:.4f}\")\n",
    "    \n",
    "    # Total Effect\n",
    "    # Row label is 'Total'\n",
    "    if 'Total' in stats_df.index:\n",
    "        total_effect_coeff = stats_df.loc['Total', 'coef']\n",
    "        total_effect_se = stats_df.loc['Total', 'se']\n",
    "        total_effect_pval = stats_df.loc['Total', 'pval']\n",
    "        total_effect_ci = [stats_df.loc['Total', 'CI[2.5%]'], stats_df.loc['Total', 'CI[97.5%]']]\n",
    "    else:\n",
    "        # Fallback\n",
    "        total_effect_coeff = stats_df.iloc[2]['coef']\n",
    "        total_effect_se = stats_df.iloc[2]['se']\n",
    "        total_effect_pval = stats_df.iloc[2]['pval']\n",
    "        total_effect_ci = [stats_df.iloc[2]['CI[2.5%]'], stats_df.iloc[2]['CI[97.5%]']]\n",
    "    \n",
    "    print(f\"\\nTotal Effect (c = c' + ab):\")\n",
    "    print(f\"  β = {total_effect_coeff:.4f} (SE: {total_effect_se:.4f})\")\n",
    "    print(f\"  95% CI: [{total_effect_ci[0]:.4f}, {total_effect_ci[1]:.4f}]\")\n",
    "    print(f\"  p-value (raw): {total_effect_pval:.4f}\")\n",
    "    \n",
    "    # Proportion Mediated\n",
    "    # Note: pingouin calculates this as indirect/total when both have same sign\n",
    "    if abs(total_effect_coeff) > 0.001:\n",
    "        prop_mediated = acme_coeff / total_effect_coeff\n",
    "        print(f\"\\nProportion Mediated:\")\n",
    "        print(f\"  Value: {prop_mediated:.3f} ({prop_mediated*100:.1f}%)\")\n",
    "    else:\n",
    "        prop_mediated = np.nan\n",
    "        print(f\"\\nProportion Mediated: Cannot calculate (total effect ≈ 0)\")\n",
    "    \n",
    "    # Test significance based on CI\n",
    "    if acme_ci[0] > 0 or acme_ci[1] < 0:\n",
    "        print(\"\\nConclusion: SIGNIFICANT mediation (BCa CI excludes zero)\")\n",
    "    else:\n",
    "        print(\"\\nConclusion: No significant mediation (BCa CI includes zero)\")\n",
    "    \n",
    "    # Store all p-values for FDR correction later\n",
    "    p_values = {\n",
    "        'path_a': path_a_pval,\n",
    "        'path_b': path_b_pval,\n",
    "        'acme': acme_pval,\n",
    "        'ade': path_c_prime_pval,\n",
    "        'total': total_effect_pval\n",
    "    }\n",
    "    \n",
    "    # Return comprehensive results\n",
    "    return {\n",
    "        'path_a': {'coeff': path_a_coeff, 'se': path_a_se, 'pval': path_a_pval, 'ci': path_a_ci},\n",
    "        'path_b': {'coeff': path_b_coeff, 'se': path_b_se, 'pval': path_b_pval, 'ci': path_b_ci},\n",
    "        'path_c_prime': {'coeff': path_c_prime_coeff, 'se': path_c_prime_se, 'pval': path_c_prime_pval, 'ci': path_c_prime_ci},\n",
    "        'acme': {'coeff': acme_coeff, 'se': acme_se, 'pval': acme_pval, 'ci': acme_ci},\n",
    "        'ade': {'coeff': path_c_prime_coeff, 'se': path_c_prime_se, 'pval': path_c_prime_pval, 'ci': path_c_prime_ci},\n",
    "        'total_effect': {'coeff': total_effect_coeff, 'se': total_effect_se, 'pval': total_effect_pval, 'ci': total_effect_ci},\n",
    "        'prop_mediated': prop_mediated,\n",
    "        'p_values': p_values,\n",
    "        'pingouin_results': stats_df\n",
    "    }\n",
    "\n",
    "# ================== PART 2: TEMPORAL COMPARISON FUNCTION ==================\n",
    "\n",
    "def compare_mediation_effects_paired_bootstrap(df, predictor, mediator_3m, mediator_6m, \n",
    "                                             outcome_3m, outcome_6m, covariate_3m, covariate_6m, \n",
    "                                             n_bootstrap=5000):\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"TEMPORAL COMPARISON - Paired Bootstrap (5000 resamples)\")\n",
    "    print(f\"Predictor: {predictor}\")\n",
    "    print(f\"Mediators: {mediator_3m} (3m), {mediator_6m} (6m)\")\n",
    "    print(f\"METHODOLOGY: Testing if indirect effects differ between 3 and 6 months\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Prepare paired data\n",
    "    required_cols_3m = [predictor, mediator_3m, outcome_3m, covariate_3m, 'Patient_ID']\n",
    "    required_cols_6m = [predictor, mediator_6m, outcome_6m, covariate_6m, 'Patient_ID']\n",
    "    \n",
    "    # Get complete cases for each timepoint\n",
    "    data_3m = df[required_cols_3m].dropna()\n",
    "    data_6m = df[required_cols_6m].dropna()\n",
    "    \n",
    "    # Find patients with data at both timepoints\n",
    "    patients_3m = set(data_3m['Patient_ID'].unique())\n",
    "    patients_6m = set(data_6m['Patient_ID'].unique())\n",
    "    common_patients = list(patients_3m.intersection(patients_6m))\n",
    "    \n",
    "    print(f\"Patients with 3-month data: {len(patients_3m)}\")\n",
    "    print(f\"Patients with 6-month data: {len(patients_6m)}\")\n",
    "    print(f\"Patients with paired data: {len(common_patients)}\")\n",
    "    \n",
    "    if len(common_patients) < 5:\n",
    "        print(\"ERROR: Insufficient paired data for temporal comparison\")\n",
    "        return None\n",
    "    \n",
    "    # Filter to common patients only\n",
    "    data_3m_paired = data_3m[data_3m['Patient_ID'].isin(common_patients)].copy()\n",
    "    data_6m_paired = data_6m[data_6m['Patient_ID'].isin(common_patients)].copy()\n",
    "    \n",
    "    # Calculate observed indirect effects\n",
    "    print(\"\\nCalculating observed indirect effects...\")\n",
    "    \n",
    "    # 3-month mediation\n",
    "    try:\n",
    "        stats_3m = pg.mediation_analysis(\n",
    "            data=data_3m_paired,\n",
    "            x=predictor,\n",
    "            m=mediator_3m,\n",
    "            y=outcome_3m,\n",
    "            covar=covariate_3m,\n",
    "            n_boot=5000,\n",
    "            seed=42,\n",
    "            return_dist=False\n",
    "        )\n",
    "        # Extract indirect effect\n",
    "        if 'Indirect' in stats_3m.index:\n",
    "            obs_ie_3m = stats_3m.loc['Indirect', 'coef']\n",
    "        else:\n",
    "            obs_ie_3m = stats_3m.iloc[4]['coef']  # Fallback to 5th row\n",
    "    except Exception as e:\n",
    "        print(f\"Error in 3-month mediation: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # 6-month mediation\n",
    "    try:\n",
    "        stats_6m = pg.mediation_analysis(\n",
    "            data=data_6m_paired,\n",
    "            x=predictor,\n",
    "            m=mediator_6m,\n",
    "            y=outcome_6m,\n",
    "            covar=covariate_6m,\n",
    "            n_boot=5000,\n",
    "            seed=42,\n",
    "            return_dist=False\n",
    "        )\n",
    "        # Extract indirect effect\n",
    "        if 'Indirect' in stats_6m.index:\n",
    "            obs_ie_6m = stats_6m.loc['Indirect', 'coef']\n",
    "        else:\n",
    "            obs_ie_6m = stats_6m.iloc[4]['coef']  # Fallback to 5th row\n",
    "    except Exception as e:\n",
    "        print(f\"Error in 6-month mediation: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Observed difference\n",
    "    obs_diff = obs_ie_6m - obs_ie_3m\n",
    "    \n",
    "    print(f\"\\nObserved indirect effects:\")\n",
    "    print(f\"  3-month: {obs_ie_3m:.4f}\")\n",
    "    print(f\"  6-month: {obs_ie_6m:.4f}\")\n",
    "    print(f\"  Difference (6m - 3m): {obs_diff:.4f}\")\n",
    "    \n",
    "    # Paired bootstrap\n",
    "    print(f\"\\nPerforming {n_bootstrap} paired bootstrap iterations...\")\n",
    "    print(\"(Resampling patients to preserve within-patient correlation)\")\n",
    "    \n",
    "    boot_differences = []\n",
    "    successful_boots = 0\n",
    "    \n",
    "    for i in range(n_bootstrap):\n",
    "        # Resample patients with replacement\n",
    "        bootstrap_patients = np.random.choice(common_patients, \n",
    "                                            size=len(common_patients), \n",
    "                                            replace=True)\n",
    "        \n",
    "        # Create bootstrap datasets by selecting resampled patients\n",
    "        boot_data_3m = []\n",
    "        boot_data_6m = []\n",
    "        \n",
    "        for patient in bootstrap_patients:\n",
    "            # Get this patient's data at both timepoints\n",
    "            patient_data_3m = data_3m_paired[data_3m_paired['Patient_ID'] == patient]\n",
    "            patient_data_6m = data_6m_paired[data_6m_paired['Patient_ID'] == patient]\n",
    "            \n",
    "            boot_data_3m.append(patient_data_3m)\n",
    "            boot_data_6m.append(patient_data_6m)\n",
    "        \n",
    "        boot_data_3m = pd.concat(boot_data_3m, ignore_index=True)\n",
    "        boot_data_6m = pd.concat(boot_data_6m, ignore_index=True)\n",
    "        \n",
    "        try:\n",
    "            # Run mediation on bootstrap samples\n",
    "            boot_stats_3m = pg.mediation_analysis(\n",
    "                data=boot_data_3m,\n",
    "                x=predictor,\n",
    "                m=mediator_3m,\n",
    "                y=outcome_3m,\n",
    "                covar=covariate_3m,\n",
    "                n_boot=5000,\n",
    "                seed=42+i,\n",
    "                return_dist=False\n",
    "            )\n",
    "            \n",
    "            boot_stats_6m = pg.mediation_analysis(\n",
    "                data=boot_data_6m,\n",
    "                x=predictor,\n",
    "                m=mediator_6m,\n",
    "                y=outcome_6m,\n",
    "                covar=covariate_6m,\n",
    "                n_boot=5000,\n",
    "                seed=42+i,\n",
    "                return_dist=False\n",
    "            )\n",
    "            \n",
    "            # Extract indirect effects\n",
    "            if 'Indirect' in boot_stats_3m.index:\n",
    "                boot_ie_3m = boot_stats_3m.loc['Indirect', 'coef']\n",
    "            else:\n",
    "                boot_ie_3m = boot_stats_3m.iloc[4]['coef']\n",
    "                \n",
    "            if 'Indirect' in boot_stats_6m.index:\n",
    "                boot_ie_6m = boot_stats_6m.loc['Indirect', 'coef']\n",
    "            else:\n",
    "                boot_ie_6m = boot_stats_6m.iloc[4]['coef']\n",
    "            \n",
    "            # Calculate difference\n",
    "            boot_diff = boot_ie_6m - boot_ie_3m\n",
    "            boot_differences.append(boot_diff)\n",
    "            successful_boots += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Handle any convergence issues\n",
    "            continue\n",
    "        \n",
    "        # Progress indicator\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"  Completed {i + 1}/{n_bootstrap} bootstrap iterations...\")\n",
    "    \n",
    "    boot_differences = np.array(boot_differences)\n",
    "    \n",
    "    print(f\"\\nSuccessful bootstrap iterations: {successful_boots}/{n_bootstrap}\")\n",
    "    \n",
    "    if len(boot_differences) < 100:\n",
    "        print(\"WARNING: Many bootstrap iterations failed. Results may be unstable.\")\n",
    "    \n",
    "    # Calculate statistics from bootstrap distribution\n",
    "    # Two-tailed p-value\n",
    "    p_value = np.mean(np.abs(boot_differences) >= np.abs(obs_diff))\n",
    "    \n",
    "    # 95% CI from bootstrap percentiles\n",
    "    ci_boot = np.percentile(boot_differences, [2.5, 97.5])\n",
    "    \n",
    "    # Bootstrap SE\n",
    "    se_boot = np.std(boot_differences)\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"PAIRED BOOTSTRAP RESULTS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Difference (6m - 3m): {obs_diff:.4f}\")\n",
    "    print(f\"Bootstrap SE: {se_boot:.4f}\")\n",
    "    print(f\"95% Bootstrap CI: [{ci_boot[0]:.4f}, {ci_boot[1]:.4f}]\")\n",
    "    print(f\"Two-tailed p-value: {p_value:.4f}\")\n",
    "    \n",
    "    # Interpret results\n",
    "    if ci_boot[0] > 0 or ci_boot[1] < 0:\n",
    "        print(\"\\nConclusion: Indirect effects DIFFER significantly between timepoints\")\n",
    "        print(\"(95% CI excludes zero)\")\n",
    "    else:\n",
    "        print(\"\\nConclusion: No significant difference in indirect effects\")\n",
    "        print(\"(95% CI includes zero)\")\n",
    "    \n",
    "    return {\n",
    "        'difference': obs_diff,\n",
    "        'se': se_boot,\n",
    "        'ci': ci_boot,\n",
    "        'p_value': p_value,\n",
    "        'bootstrap_differences': boot_differences,\n",
    "        'n_patients': len(common_patients),\n",
    "        'n_successful_boots': successful_boots\n",
    "    }\n",
    "\n",
    "# ================== PART 3: CLINICAL PREDICTIVE UTILITY WITH MIXED MODELS ==================\n",
    "\n",
    "def clinical_predictive_utility_mixed(df, hdp_predictor, hdp_type_name):\n",
    "    \"\"\"\n",
    "    Assess incremental predictive value of HDP beyond levodopa response.\n",
    "    \n",
    "    METHODOLOGY SECTION: Stage 3 - Clinical Predictive Utility Analysis\n",
    "    \"Model 1: UPDRS_Change = γ₀ + γ₁·Levodopa_z + γ₂·Time + tau_i + ε\n",
    "     Model 2: UPDRS_Change = γ₀ + γ₁·Levodopa_z + γ₂·HDP_z + γ₃·Time + tau_i + ε\"\n",
    "    \n",
    "    Uses mixed linear models with random intercepts (tau_i) as specified.\n",
    "    Implements leave-one-patient-out cross-validation.\n",
    "    \n",
    "    **UPDATED**: Now returns individual patient MSE values for paired plotting.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CLINICAL PREDICTIVE UTILITY ANALYSIS - {hdp_type_name}\")\n",
    "    print(f\"Using predictor: {hdp_predictor}\")\n",
    "    print(f\"METHODOLOGY: Mixed models with random intercepts + LOO-CV\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Data preparation as specified in methodology\n",
    "    if df[hdp_predictor].isna().all():\n",
    "        print(f\"WARNING: All values for {hdp_predictor} are NaN. Skipping.\")\n",
    "        return None\n",
    "    \n",
    "    # Prepare pooled data with Time coded as 0 (3 months) or 1 (6 months)\n",
    "    data_3m = df[[hdp_predictor, 'Levodopa_Response', 'UPDRS_Change_3m', 'Patient_ID']].dropna().copy()\n",
    "    data_3m['Time'] = 0  # As specified in methodology\n",
    "    data_3m.rename(columns={'UPDRS_Change_3m': 'UPDRS_Change'}, inplace=True)\n",
    "    \n",
    "    data_6m = df[[hdp_predictor, 'Levodopa_Response', 'UPDRS_Change_6m', 'Patient_ID']].dropna().copy()\n",
    "    data_6m['Time'] = 1  # As specified in methodology\n",
    "    data_6m.rename(columns={'UPDRS_Change_6m': 'UPDRS_Change'}, inplace=True)\n",
    "    \n",
    "    pooled_data = pd.concat([data_3m, data_6m], ignore_index=True)\n",
    "    \n",
    "    print(f\"Sample sizes: 3-month n={len(data_3m)}, 6-month n={len(data_6m)}, Pooled n={len(pooled_data)}\")\n",
    "    \n",
    "    if len(pooled_data) < 10:\n",
    "        print(f\"WARNING: Insufficient data (n={len(pooled_data)}). Skipping.\")\n",
    "        return None\n",
    "    \n",
    "    # Standardize predictors (z-score) as specified\n",
    "    scaler = StandardScaler()\n",
    "    pooled_data['HDP_z'] = scaler.fit_transform(pooled_data[[hdp_predictor]])\n",
    "    pooled_data['Levodopa_z'] = scaler.fit_transform(pooled_data[['Levodopa_Response']])\n",
    "    \n",
    "    # Save scalers for sensitivity analysis\n",
    "    hdp_scaler = StandardScaler().fit(pooled_data[[hdp_predictor]])\n",
    "    levo_scaler = StandardScaler().fit(pooled_data[['Levodopa_Response']])\n",
    "    \n",
    "    # Check multicollinearity using variance_inflation_factor\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"MULTICOLLINEARITY CHECK\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Calculate VIF properly using statsmodels\n",
    "    from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "    \n",
    "    X_vif = pooled_data[['Levodopa_z', 'HDP_z']].values\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Variable\"] = ['Levodopa_z', 'HDP_z']\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X_vif, i) for i in range(X_vif.shape[1])]\n",
    "    \n",
    "    print(\"\\nVariance Inflation Factors:\")\n",
    "    print(vif_data)\n",
    "    \n",
    "    if any(vif_data[\"VIF\"] > 5):\n",
    "        print(\"\\nWARNING: High multicollinearity detected (VIF > 5)\")\n",
    "    \n",
    "    # ===== MAIN ANALYSIS: POOLED WITH RANDOM EFFECTS =====\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"MAIN ANALYSIS: POOLED MIXED MODELS\")\n",
    "    print(\"METHODOLOGY: Testing γ₂ = 0 with Z-test\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Model 1: As specified in methodology\n",
    "    formula1 = 'UPDRS_Change ~ Levodopa_z + Time'\n",
    "    model1 = smf.mixedlm(formula1, data=pooled_data, groups=pooled_data['Patient_ID']).fit()\n",
    "    \n",
    "    print(\"\\nModel 1 (Levodopa + Time + Random Intercepts):\")\n",
    "    print(f\"Formula: {formula1}\")\n",
    "    print(f\"Log-likelihood: {model1.llf:.2f}\")\n",
    "    print(f\"AIC: {model1.aic:.2f}, BIC: {model1.bic:.2f}\")\n",
    "    \n",
    "    # Model 2: As specified in methodology\n",
    "    formula2 = 'UPDRS_Change ~ Levodopa_z + HDP_z + Time'\n",
    "    model2 = smf.mixedlm(formula2, data=pooled_data, groups=pooled_data['Patient_ID']).fit()\n",
    "    \n",
    "    print(\"\\nModel 2 (Levodopa + HDP + Time + Random Intercepts):\")\n",
    "    print(f\"Formula: {formula2}\")\n",
    "    print(f\"Log-likelihood: {model2.llf:.2f}\")\n",
    "    print(f\"AIC: {model2.aic:.2f}, BIC: {model2.bic:.2f}\")\n",
    "    \n",
    "    # Z-test for HDP coefficient as specified\n",
    "    hdp_coef = model2.params['HDP_z']\n",
    "    hdp_se = model2.bse['HDP_z']\n",
    "    z_stat = hdp_coef / hdp_se\n",
    "    p_value_z = 2 * (1 - stats.norm.cdf(abs(z_stat)))\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Z-TEST FOR HDP COEFFICIENT (γ₂ = 0)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"HDP coefficient (γ₂): {hdp_coef:.4f}\")\n",
    "    print(f\"Standard error: {hdp_se:.4f}\")\n",
    "    print(f\"Z-statistic: {z_stat:.3f}\")\n",
    "    print(f\"P-value (raw): {p_value_z:.4f}\")\n",
    "    \n",
    "    # Variance components as specified\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"VARIANCE COMPONENTS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    random_var = model2.cov_re.iloc[0, 0]\n",
    "    residual_var = model2.scale\n",
    "    icc = random_var / (random_var + residual_var)\n",
    "    print(f\"Random Effect Variance (τ²): {random_var:.3f}\")\n",
    "    print(f\"Residual Variance (σ²): {residual_var:.3f}\")\n",
    "    print(f\"Intraclass Correlation Coefficient (ICC): {icc:.3f}\")\n",
    "    \n",
    "    # ===== LEAVE-ONE-PATIENT-OUT CROSS-VALIDATION =====\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"LEAVE-ONE-PATIENT-OUT CROSS-VALIDATION\")\n",
    "    print(\"METHODOLOGY: Using sklearn's LeaveOneOut for proper implementation\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Group by patient for LOO\n",
    "    patients = pooled_data['Patient_ID'].unique()\n",
    "    \n",
    "    # Initialize LOO cross-validator\n",
    "    loo = LeaveOneOut()\n",
    "    \n",
    "    # Store predictions and actuals\n",
    "    cv_results_model1 = []\n",
    "    cv_results_model2 = []\n",
    "    \n",
    "    # Create patient indices for LOO\n",
    "    patient_indices = []\n",
    "    for patient in patients:\n",
    "        patient_indices.append(pooled_data[pooled_data['Patient_ID'] == patient].index.tolist())\n",
    "    \n",
    "    # Perform LOO-CV\n",
    "    for train_patients, test_patient in loo.split(patients):\n",
    "        # Get train and test indices\n",
    "        train_idx = []\n",
    "        for p_idx in train_patients:\n",
    "            train_idx.extend(patient_indices[p_idx])\n",
    "        test_idx = patient_indices[test_patient[0]]\n",
    "        \n",
    "        # Split data\n",
    "        train_data = pooled_data.iloc[train_idx].copy()\n",
    "        test_data = pooled_data.iloc[test_idx].copy()\n",
    "        \n",
    "        if len(test_data) == 0 or len(train_data) < 10:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Fit models on training data\n",
    "            model1_train = smf.mixedlm(formula1, data=train_data, groups=train_data['Patient_ID']).fit()\n",
    "            model2_train = smf.mixedlm(formula2, data=train_data, groups=train_data['Patient_ID']).fit()\n",
    "            \n",
    "            # Predict for test patient (fixed effects only for new patient)\n",
    "            # Model 1\n",
    "            test_design1 = np.column_stack([\n",
    "                np.ones(len(test_data)),\n",
    "                test_data['Levodopa_z'].values,\n",
    "                test_data['Time'].values\n",
    "            ])\n",
    "            pred1 = np.dot(test_design1, model1_train.fe_params)\n",
    "            \n",
    "            # Model 2\n",
    "            test_design2 = np.column_stack([\n",
    "                np.ones(len(test_data)),\n",
    "                test_data['Levodopa_z'].values,\n",
    "                test_data['HDP_z'].values,\n",
    "                test_data['Time'].values\n",
    "            ])\n",
    "            pred2 = np.dot(test_design2, model2_train.fe_params)\n",
    "            \n",
    "            actual = test_data['UPDRS_Change'].values\n",
    "            \n",
    "            # Calculate MSE\n",
    "            mse1 = mean_squared_error(actual, pred1)\n",
    "            mse2 = mean_squared_error(actual, pred2)\n",
    "            \n",
    "            cv_results_model1.append({'patient': patients[test_patient[0]], 'mse': mse1})\n",
    "            cv_results_model2.append({'patient': patients[test_patient[0]], 'mse': mse2})\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in CV for patient {patients[test_patient[0]]}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    cv_df_model1 = pd.DataFrame(cv_results_model1)\n",
    "    cv_df_model2 = pd.DataFrame(cv_results_model2)\n",
    "    \n",
    "    # Print individual patient MSE values for plotting\n",
    "    print(\"\\n--- INDIVIDUAL PATIENT MSE VALUES ---\")\n",
    "    print(\"Patient ID, Model 1 (Levo), Model 2 (Levo+HDP)\")\n",
    "    print(\"-\" * 45)\n",
    "    \n",
    "    # Merge the dataframes to ensure paired values\n",
    "    if len(cv_df_model1) > 0 and len(cv_df_model2) > 0:\n",
    "        cv_merged = pd.merge(cv_df_model1, cv_df_model2, on='patient', suffixes=('_model1', '_model2'))\n",
    "        for _, row in cv_merged.iterrows():\n",
    "            print(f\"{row['patient']:10}, {row['mse_model1']:.6f}, {row['mse_model2']:.6f}\")\n",
    "        \n",
    "        mse_pooled_model1 = cv_df_model1['mse'].mean()\n",
    "        mse_pooled_model2 = cv_df_model2['mse'].mean()\n",
    "        print(f\"\\nCross-validation results (n={len(cv_results_model1)} patients):\")\n",
    "        print(f\"Mean MSE Model 1 (Levodopa only): {mse_pooled_model1:.6f}\")\n",
    "        print(f\"Mean MSE Model 2 (Levodopa + HDP): {mse_pooled_model2:.6f}\")\n",
    "        improvement_pct = (mse_pooled_model1 - mse_pooled_model2) / mse_pooled_model1 * 100\n",
    "        print(f\"Improvement: {improvement_pct:.1f}%\")\n",
    "    else:\n",
    "        print(\"\\nInsufficient data for pooled cross-validation\")\n",
    "        mse_pooled_model1 = np.nan\n",
    "        mse_pooled_model2 = np.nan\n",
    "        cv_merged = pd.DataFrame()\n",
    "    \n",
    "    # ===== SENSITIVITY ANALYSIS: SEPARATE TIMEPOINTS =====\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"SENSITIVITY ANALYSIS: SEPARATE TIMEPOINTS (NO RANDOM EFFECTS)\")\n",
    "    print(\"METHODOLOGY: OLS at each timepoint separately\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # 3-month analysis\n",
    "    print(\"\\n--- 3-MONTH ANALYSIS ---\")\n",
    "    mse_3m_model1 = np.nan\n",
    "    mse_3m_model2 = np.nan\n",
    "    p_value_3m = np.nan\n",
    "    \n",
    "    if len(data_3m) >= 5:\n",
    "        # Standardize using pooled scalers\n",
    "        data_3m['HDP_z'] = hdp_scaler.transform(data_3m[[hdp_predictor]])\n",
    "        data_3m['Levodopa_z'] = levo_scaler.transform(data_3m[['Levodopa_Response']])\n",
    "        \n",
    "        # OLS models (no Time variable as we're analyzing separately)\n",
    "        X1_3m = sm.add_constant(data_3m[['Levodopa_z']])\n",
    "        model1_3m = sm.OLS(data_3m['UPDRS_Change'], X1_3m).fit()\n",
    "        \n",
    "        X2_3m = sm.add_constant(data_3m[['Levodopa_z', 'HDP_z']])\n",
    "        model2_3m = sm.OLS(data_3m['UPDRS_Change'], X2_3m).fit()\n",
    "        \n",
    "        print(f\"Model 1 R²: {model1_3m.rsquared:.3f}\")\n",
    "        print(f\"Model 2 R²: {model2_3m.rsquared:.3f}\")\n",
    "        \n",
    "        # Use t-test p-value from OLS (appropriate for small samples)\n",
    "        if 'HDP_z' in model2_3m.params:\n",
    "            hdp_coef_3m = model2_3m.params['HDP_z']\n",
    "            hdp_se_3m = model2_3m.bse['HDP_z']\n",
    "            t_stat_3m = model2_3m.tvalues['HDP_z']\n",
    "            p_value_3m = model2_3m.pvalues['HDP_z']  # This is the t-test p-value\n",
    "            print(f\"HDP coefficient: {hdp_coef_3m:.4f}, t={t_stat_3m:.3f}, p={p_value_3m:.4f}\")\n",
    "        \n",
    "        # LOO-CV for both models\n",
    "        loo_3m = LeaveOneOut()\n",
    "        X_3m_model1 = data_3m[['Levodopa_z']].values\n",
    "        X_3m_model2 = data_3m[['Levodopa_z', 'HDP_z']].values\n",
    "        y_3m = data_3m['UPDRS_Change'].values\n",
    "        \n",
    "        # Model 1 LOO-CV\n",
    "        predictions_3m_model1 = []\n",
    "        for train_idx, test_idx in loo_3m.split(X_3m_model1):\n",
    "            X_train = sm.add_constant(X_3m_model1[train_idx])\n",
    "            X_test = sm.add_constant(X_3m_model1[test_idx])\n",
    "            y_train = y_3m[train_idx]\n",
    "            model_cv = sm.OLS(y_train, X_train).fit()\n",
    "            pred = model_cv.predict(X_test)\n",
    "            predictions_3m_model1.extend(pred)\n",
    "        \n",
    "        mse_3m_model1 = mean_squared_error(y_3m, predictions_3m_model1)\n",
    "        \n",
    "        # Model 2 LOO-CV\n",
    "        predictions_3m_model2 = []\n",
    "        for train_idx, test_idx in loo_3m.split(X_3m_model2):\n",
    "            X_train = sm.add_constant(X_3m_model2[train_idx])\n",
    "            X_test = sm.add_constant(X_3m_model2[test_idx])\n",
    "            y_train = y_3m[train_idx]\n",
    "            model_cv = sm.OLS(y_train, X_train).fit()\n",
    "            pred = model_cv.predict(X_test)\n",
    "            predictions_3m_model2.extend(pred)\n",
    "        \n",
    "        mse_3m_model2 = mean_squared_error(y_3m, predictions_3m_model2)\n",
    "        \n",
    "        print(f\"\\n3-month LOO-CV MSE:\")\n",
    "        print(f\"  Model 1 (Levodopa only): {mse_3m_model1:.6f}\")\n",
    "        print(f\"  Model 2 (Levodopa + HDP): {mse_3m_model2:.6f}\")\n",
    "        print(f\"  Improvement: {(mse_3m_model1 - mse_3m_model2) / mse_3m_model1 * 100:.1f}%\")\n",
    "    \n",
    "    # 6-month analysis\n",
    "    print(\"\\n--- 6-MONTH ANALYSIS ---\")\n",
    "    mse_6m_model1 = np.nan\n",
    "    mse_6m_model2 = np.nan\n",
    "    p_value_6m = np.nan\n",
    "    \n",
    "    if len(data_6m) >= 5:\n",
    "        # Similar analysis for 6 months...\n",
    "        data_6m['HDP_z'] = hdp_scaler.transform(data_6m[[hdp_predictor]])\n",
    "        data_6m['Levodopa_z'] = levo_scaler.transform(data_6m[['Levodopa_Response']])\n",
    "        \n",
    "        X1_6m = sm.add_constant(data_6m[['Levodopa_z']])\n",
    "        model1_6m = sm.OLS(data_6m['UPDRS_Change'], X1_6m).fit()\n",
    "        \n",
    "        X2_6m = sm.add_constant(data_6m[['Levodopa_z', 'HDP_z']])\n",
    "        model2_6m = sm.OLS(data_6m['UPDRS_Change'], X2_6m).fit()\n",
    "        \n",
    "        print(f\"Model 1 R²: {model1_6m.rsquared:.3f}\")\n",
    "        print(f\"Model 2 R²: {model2_6m.rsquared:.3f}\")\n",
    "        \n",
    "        # Use t-test p-value from OLS\n",
    "        if 'HDP_z' in model2_6m.params:\n",
    "            hdp_coef_6m = model2_6m.params['HDP_z']\n",
    "            hdp_se_6m = model2_6m.bse['HDP_z']\n",
    "            t_stat_6m = model2_6m.tvalues['HDP_z']\n",
    "            p_value_6m = model2_6m.pvalues['HDP_z']  # This is the t-test p-value\n",
    "            print(f\"HDP coefficient: {hdp_coef_6m:.4f}, t={t_stat_6m:.3f}, p={p_value_6m:.4f}\")\n",
    "        \n",
    "        # LOO-CV for both models\n",
    "        loo_6m = LeaveOneOut()\n",
    "        X_6m_model1 = data_6m[['Levodopa_z']].values\n",
    "        X_6m_model2 = data_6m[['Levodopa_z', 'HDP_z']].values\n",
    "        y_6m = data_6m['UPDRS_Change'].values\n",
    "        \n",
    "        # Model 1 LOO-CV\n",
    "        predictions_6m_model1 = []\n",
    "        for train_idx, test_idx in loo_6m.split(X_6m_model1):\n",
    "            X_train = sm.add_constant(X_6m_model1[train_idx])\n",
    "            X_test = sm.add_constant(X_6m_model1[test_idx])\n",
    "            y_train = y_6m[train_idx]\n",
    "            model_cv = sm.OLS(y_train, X_train).fit()\n",
    "            pred = model_cv.predict(X_test)\n",
    "            predictions_6m_model1.extend(pred)\n",
    "        \n",
    "        mse_6m_model1 = mean_squared_error(y_6m, predictions_6m_model1)\n",
    "        \n",
    "        # Model 2 LOO-CV\n",
    "        predictions_6m_model2 = []\n",
    "        for train_idx, test_idx in loo_6m.split(X_6m_model2):\n",
    "            X_train = sm.add_constant(X_6m_model2[train_idx])\n",
    "            X_test = sm.add_constant(X_6m_model2[test_idx])\n",
    "            y_train = y_6m[train_idx]\n",
    "            model_cv = sm.OLS(y_train, X_train).fit()\n",
    "            pred = model_cv.predict(X_test)\n",
    "            predictions_6m_model2.extend(pred)\n",
    "        \n",
    "        mse_6m_model2 = mean_squared_error(y_6m, predictions_6m_model2)\n",
    "        \n",
    "        print(f\"\\n6-month LOO-CV MSE:\")\n",
    "        print(f\"  Model 1 (Levodopa only): {mse_6m_model1:.6f}\")\n",
    "        print(f\"  Model 2 (Levodopa + HDP): {mse_6m_model2:.6f}\")\n",
    "        print(f\"  Improvement: {(mse_6m_model1 - mse_6m_model2) / mse_6m_model1 * 100:.1f}%\")\n",
    "    \n",
    "    # ===== FINAL COMPARISON =====\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"FINAL MSE COMPARISON\")\n",
    "    print(\"METHODOLOGY: Determine best approach (pooled vs separate)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"MSE Pooled Model 2 (Mixed Model): {mse_pooled_model2:.6f}\")\n",
    "    print(f\"MSE 3-month Model 2 (OLS): {mse_3m_model2:.6f}\")\n",
    "    print(f\"MSE 6-month Model 2 (OLS): {mse_6m_model2:.6f}\")\n",
    "    \n",
    "    # Determine best approach\n",
    "    mse_values = {'Pooled': mse_pooled_model2, '3-month': mse_3m_model2, '6-month': mse_6m_model2}\n",
    "    valid_mse = {k: v for k, v in mse_values.items() if not np.isnan(v)}\n",
    "    \n",
    "    if valid_mse:\n",
    "        best_approach = min(valid_mse, key=valid_mse.get)\n",
    "        print(f\"\\nBest approach: {best_approach} (lowest MSE)\")\n",
    "    \n",
    "    # Collect all p-values for this analysis\n",
    "    p_values_clinical = {\n",
    "        'mixed_model': p_value_z,\n",
    "        '3_month_ols': p_value_3m,\n",
    "        '6_month_ols': p_value_6m\n",
    "    }\n",
    "    \n",
    "    # Include individual patient MSE data in results\n",
    "    return {\n",
    "        'hdp_type': hdp_type_name,\n",
    "        'models': {'model1': model1, 'model2': model2},\n",
    "        'z_test': {\n",
    "            'coefficient': hdp_coef,\n",
    "            'se': hdp_se,\n",
    "            'z_stat': z_stat,\n",
    "            'p_value': p_value_z\n",
    "        },\n",
    "        'variance_components': {\n",
    "            'random_variance': random_var,\n",
    "            'residual_variance': residual_var,\n",
    "            'icc': icc\n",
    "        },\n",
    "        'mse_comparison': {\n",
    "            'pooled_model1': mse_pooled_model1,\n",
    "            'pooled_model2': mse_pooled_model2,\n",
    "            '3_month_model1': mse_3m_model1,\n",
    "            '3_month_model2': mse_3m_model2,\n",
    "            '6_month_model1': mse_6m_model1,\n",
    "            '6_month_model2': mse_6m_model2\n",
    "        },\n",
    "        'cv_results': {\n",
    "            'pooled_model1': cv_df_model1 if len(cv_df_model1) > 0 else None,\n",
    "            'pooled_model2': cv_df_model2 if len(cv_df_model2) > 0 else None,\n",
    "            'pooled_paired': cv_merged if len(cv_merged) > 0 else None  # NEW: paired results\n",
    "        },\n",
    "        'p_values': p_values_clinical\n",
    "    }\n",
    "\n",
    "# ================== FDR CORRECTION FUNCTION ==================\n",
    "\n",
    "def apply_fdr_correction(all_p_values, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Apply False Discovery Rate correction to all p-values.\n",
    "    \n",
    "    METHODOLOGY NOTE: This extends our analysis plan to include FDR\n",
    "    in addition to Bonferroni correction, providing better balance\n",
    "    between Type I and Type II error control.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"MULTIPLE COMPARISON CORRECTION\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Flatten all p-values into categories\n",
    "    mediation_pvals = []\n",
    "    temporal_pvals = []\n",
    "    clinical_pvals = []\n",
    "    \n",
    "    labels_mediation = []\n",
    "    labels_temporal = []\n",
    "    labels_clinical = []\n",
    "    \n",
    "    for key, pval_dict in all_p_values['mediation'].items():\n",
    "        if pval_dict is not None:\n",
    "            mediation_pvals.extend([\n",
    "                pval_dict.get('path_a', np.nan),\n",
    "                pval_dict.get('path_b', np.nan),\n",
    "                pval_dict.get('acme', np.nan),\n",
    "                pval_dict.get('ade', np.nan),\n",
    "                pval_dict.get('total', np.nan)\n",
    "            ])\n",
    "            labels_mediation.extend([\n",
    "                f\"{key}_path_a\",\n",
    "                f\"{key}_path_b\",\n",
    "                f\"{key}_acme\",\n",
    "                f\"{key}_ade\",\n",
    "                f\"{key}_total\"\n",
    "            ])\n",
    "    \n",
    "    for key, pval in all_p_values['temporal'].items():\n",
    "        if pval is not None:\n",
    "            temporal_pvals.append(pval)\n",
    "            labels_temporal.append(key)\n",
    "    \n",
    "    for key, pval_dict in all_p_values['clinical'].items():\n",
    "        if pval_dict is not None:\n",
    "            clinical_pvals.extend([\n",
    "                pval_dict.get('mixed_model', np.nan),\n",
    "                pval_dict.get('3_month_ols', np.nan),\n",
    "                pval_dict.get('6_month_ols', np.nan)\n",
    "            ])\n",
    "            labels_clinical.extend([\n",
    "                f\"{key}_mixed\",\n",
    "                f\"{key}_3m\",\n",
    "                f\"{key}_6m\"\n",
    "            ])\n",
    "    \n",
    "    # Apply FDR correction within each family\n",
    "    results = {}\n",
    "    \n",
    "    # Mediation tests\n",
    "    if len(mediation_pvals) > 0:\n",
    "        mediation_pvals_clean = [p for p in mediation_pvals if not np.isnan(p)]\n",
    "        labels_clean = [l for l, p in zip(labels_mediation, mediation_pvals) if not np.isnan(p)]\n",
    "        \n",
    "        if len(mediation_pvals_clean) > 0:\n",
    "            reject, pvals_fdr, _, _ = multipletests(mediation_pvals_clean, alpha=alpha, method='fdr_bh')\n",
    "            print(\"MEDIATION ANALYSIS - FDR Correction (Benjamini-Hochberg):\")\n",
    "            print(f\"Number of tests: {len(mediation_pvals_clean)}\")\n",
    "            print(f\"FDR threshold: {alpha}\")\n",
    "            results['mediation_fdr'] = dict(zip(labels_clean, pvals_fdr))\n",
    "            # Show significant results\n",
    "            sig_count = sum(reject)\n",
    "            print(f\"Significant after FDR: {sig_count}/{len(mediation_pvals_clean)}\")\n",
    "    \n",
    "    # Temporal comparisons\n",
    "    if len(temporal_pvals) > 0:\n",
    "        temporal_pvals_clean = [p for p in temporal_pvals if not np.isnan(p)]\n",
    "        labels_clean = [l for l, p in zip(labels_temporal, temporal_pvals) if not np.isnan(p)]\n",
    "        \n",
    "        if len(temporal_pvals_clean) > 0:\n",
    "            reject, pvals_fdr, _, _ = multipletests(temporal_pvals_clean, alpha=alpha, method='fdr_bh')\n",
    "            print(\"\\nTEMPORAL COMPARISONS - FDR Correction:\")\n",
    "            print(f\"Number of tests: {len(temporal_pvals_clean)}\")\n",
    "            results['temporal_fdr'] = dict(zip(labels_clean, pvals_fdr))\n",
    "            print(f\"Significant after FDR: {sum(reject)}/{len(temporal_pvals_clean)}\")\n",
    "    \n",
    "    # Clinical utility\n",
    "    if len(clinical_pvals) > 0:\n",
    "        clinical_pvals_clean = [p for p in clinical_pvals if not np.isnan(p)]\n",
    "        labels_clean = [l for l, p in zip(labels_clinical, clinical_pvals) if not np.isnan(p)]\n",
    "        \n",
    "        if len(clinical_pvals_clean) > 0:\n",
    "            reject, pvals_fdr, _, _ = multipletests(clinical_pvals_clean, alpha=alpha, method='fdr_bh')\n",
    "            print(\"\\nCLINICAL UTILITY - FDR Correction:\")\n",
    "            print(f\"Number of tests: {len(clinical_pvals_clean)}\")\n",
    "            results['clinical_fdr'] = dict(zip(labels_clean, pvals_fdr))\n",
    "            print(f\"Significant after FDR: {sum(reject)}/{len(clinical_pvals_clean)}\")\n",
    "    \n",
    "    # Also show Bonferroni thresholds as mentioned in methodology\n",
    "    print(\"\\nBONFERRONI THRESHOLDS (as specified in methodology):\")\n",
    "    print(f\"- Mediation: α = 0.05/{len(mediation_pvals_clean) if mediation_pvals_clean else 1} = \"\n",
    "          f\"{0.05/len(mediation_pvals_clean) if mediation_pvals_clean else 0.05:.4f}\")\n",
    "    print(f\"- Clinical utility: α = 0.05/3 = 0.017\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ================== VISUALIZATION FUNCTIONS ==================\n",
    "\n",
    "def create_comprehensive_visualizations(all_results):\n",
    "    \"\"\"\n",
    "    Create comprehensive visualization of all results with both raw and FDR p-values.\n",
    "    \"\"\"\n",
    "    print(\"\\nVisualization creation would include both raw and FDR-corrected p-values...\")\n",
    "    # Implementation omitted for brevity but would follow same structure\n",
    "\n",
    "# ================== MAIN EXECUTION ==================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Execute complete analysis pipeline EXACTLY as specified in methodology.\n",
    "    Uses established statistical packages throughout.\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"COMPREHENSIVE DBS ANALYSIS\")\n",
    "    print(\"Using Established Statistical Packages\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nPackages used:\")\n",
    "    print(\"- pingouin 0.5.3+: Mediation analysis with BCa bootstrap\")\n",
    "    print(\"- statsmodels 0.14.0+: Mixed models, OLS, VIF, FDR correction\")\n",
    "    print(\"- scikit-learn 1.0.0+: StandardScaler, LeaveOneOut CV\")\n",
    "    print(\"- scipy 1.9.0+: Statistical distributions\")\n",
    "    print(\"- pandas, numpy: Data manipulation\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Load data\n",
    "    print(\"\\nLoading data...\")\n",
    "    df = pd.read_csv('lfp_dataframe.csv')\n",
    "    \n",
    "    # Add Patient_ID if not present\n",
    "    if 'Patient_ID' not in df.columns:\n",
    "        df['Patient_ID'] = range(len(df))\n",
    "    \n",
    "    # Create synthetic Levodopa_Response if not present\n",
    "    if 'Levodopa_Response' not in df.columns:\n",
    "        print(\"\\nWARNING: Creating synthetic Levodopa_Response data\")\n",
    "        np.random.seed(42)\n",
    "        df['Levodopa_Response'] = 30 + np.random.normal(20, 15, len(df))\n",
    "        df['Levodopa_Response'] = np.clip(df['Levodopa_Response'], 10, 80)\n",
    "    \n",
    "    # Define variables as in methodology\n",
    "    hdp_types = ['M1', 'SMA', 'PFC']\n",
    "    hdp_predictors_stage1 = ['HDP_M1_Count', 'HDP_SMA_Count', 'HDP_PFC_Count']\n",
    "    hdp_predictors_stage3 = ['pre_HDP_M1_Count', 'pre_HDP_SMA_Count', 'pre_HDP_PFC_Count']\n",
    "    \n",
    "    beta_mediators_3m = {\n",
    "        'Total': 'Total_Beta_Suppression_3m',\n",
    "        'Low': 'Low_Beta_Suppression_3m',\n",
    "        'High': 'High_Beta_Suppression_3m'\n",
    "    }\n",
    "    beta_mediators_6m = {\n",
    "        'Total': 'Total_Beta_Suppression_6m',\n",
    "        'Low': 'Low_Beta_Suppression_6m',\n",
    "        'High': 'High_Beta_Suppression_6m'\n",
    "    }\n",
    "    \n",
    "    # Change Stimulation_Strength columns to Dosage\n",
    "    df.rename(columns={\n",
    "        'Stimulation_Strength_3m': 'Dosage_3m',\n",
    "        'Stimulation_Strength_6m': 'Dosage_6m'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Store all results and p-values\n",
    "    all_results = {\n",
    "        'mediation_3m': {},\n",
    "        'mediation_6m': {},\n",
    "        'temporal_comparisons': {},\n",
    "        'clinical_utility': {}\n",
    "    }\n",
    "    \n",
    "    all_p_values = {\n",
    "        'mediation': {},\n",
    "        'temporal': {},\n",
    "        'clinical': {}\n",
    "    }\n",
    "    \n",
    "    # ===== STAGE 1 & 2: MEDIATION ANALYSIS =====\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"STAGE 1 & 2: MEDIATION ANALYSIS\")\n",
    "    print(\"METHODOLOGY: Baron & Kenny with BCa bootstrap (5000 resamples)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for hdp_idx, (hdp_predictor, hdp_type) in enumerate(zip(hdp_predictors_stage1, hdp_types)):\n",
    "        print(f\"\\n\\n{'='*80}\")\n",
    "        print(f\"ANALYZING HDP TYPE: {hdp_type}\")\n",
    "        print(f\"Using predictor: {hdp_predictor}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        if hdp_predictor not in df.columns:\n",
    "            print(f\"WARNING: {hdp_predictor} not found in data. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        if df[hdp_predictor].isna().all():\n",
    "            print(f\"WARNING: All values for {hdp_predictor} are NaN. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Analyze each beta band\n",
    "        for beta_type, mediator_3m in beta_mediators_3m.items():\n",
    "            mediator_6m = beta_mediators_6m[beta_type]\n",
    "            \n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(f\"BETA BAND: {beta_type}\")\n",
    "            print(f\"{'='*70}\")\n",
    "            \n",
    "            # 3-month analysis\n",
    "            print(f\"\\n### 3-MONTH ANALYSIS - {hdp_type} → {beta_type} Beta ###\")\n",
    "            required_cols_3m = [hdp_predictor, mediator_3m, 'UPDRS_Change_3m', 'Dosage_3m']\n",
    "            \n",
    "            if all(col in df.columns for col in required_cols_3m):\n",
    "                data_3m = df[required_cols_3m].dropna()\n",
    "                \n",
    "                if len(data_3m) >= 5:\n",
    "                    results_3m = run_mediation_analysis_complete(\n",
    "                        data_3m,\n",
    "                        predictor=hdp_predictor,\n",
    "                        mediator=mediator_3m,\n",
    "                        outcome='UPDRS_Change_3m',\n",
    "                        covariate='Dosage_3m'\n",
    "                    )\n",
    "                    \n",
    "                    if results_3m is not None:\n",
    "                        key = f'{hdp_predictor}_{beta_type}_Beta'\n",
    "                        all_results['mediation_3m'][key] = results_3m\n",
    "                        all_p_values['mediation'][f\"{key}_3m\"] = results_3m['p_values']\n",
    "                else:\n",
    "                    print(f\"Insufficient data for 3-month analysis (n={len(data_3m)})\")\n",
    "            else:\n",
    "                print(f\"Missing columns for 3-month analysis\")\n",
    "            \n",
    "            # 6-month analysis\n",
    "            print(f\"\\n### 6-MONTH ANALYSIS - {hdp_type} → {beta_type} Beta ###\")\n",
    "            required_cols_6m = [hdp_predictor, mediator_6m, 'UPDRS_Change_6m', 'Dosage_6m']\n",
    "            \n",
    "            if all(col in df.columns for col in required_cols_6m):\n",
    "                data_6m = df[required_cols_6m].dropna()\n",
    "                \n",
    "                if len(data_6m) >= 5:\n",
    "                    results_6m = run_mediation_analysis_complete(\n",
    "                        data_6m,\n",
    "                        predictor=hdp_predictor,\n",
    "                        mediator=mediator_6m,\n",
    "                        outcome='UPDRS_Change_6m',\n",
    "                        covariate='Dosage_6m'\n",
    "                    )\n",
    "                    \n",
    "                    if results_6m is not None:\n",
    "                        key = f'{hdp_predictor}_{beta_type}_Beta'\n",
    "                        all_results['mediation_6m'][key] = results_6m\n",
    "                        all_p_values['mediation'][f\"{key}_6m\"] = results_6m['p_values']\n",
    "                else:\n",
    "                    print(f\"Insufficient data for 6-month analysis (n={len(data_6m)})\")\n",
    "            else:\n",
    "                print(f\"Missing columns for 6-month analysis\")\n",
    "            \n",
    "            # Temporal comparison\n",
    "            key = f'{hdp_predictor}_{beta_type}_Beta'\n",
    "            if key in all_results['mediation_3m'] and key in all_results['mediation_6m']:\n",
    "                print(f\"\\n### TEMPORAL COMPARISON - {hdp_type} → {beta_type} Beta ###\")\n",
    "                \n",
    "                temporal_results = compare_mediation_effects_paired_bootstrap(\n",
    "                    df,\n",
    "                    predictor=hdp_predictor,\n",
    "                    mediator_3m=mediator_3m,\n",
    "                    mediator_6m=mediator_6m,\n",
    "                    outcome_3m='UPDRS_Change_3m',\n",
    "                    outcome_6m='UPDRS_Change_6m',\n",
    "                    covariate_3m='Dosage_3m',\n",
    "                    covariate_6m='Dosage_6m'\n",
    "                )\n",
    "                \n",
    "                if temporal_results is not None:\n",
    "                    all_results['temporal_comparisons'][key] = temporal_results\n",
    "                    all_p_values['temporal'][key] = temporal_results['p_value']\n",
    "    \n",
    "    # ===== STAGE 3: CLINICAL PREDICTIVE UTILITY =====\n",
    "    print(\"\\n\\n\" + \"=\"*80)\n",
    "    print(\"STAGE 3: CLINICAL PREDICTIVE UTILITY\")\n",
    "    print(\"METHODOLOGY: Mixed models with random intercepts\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for hdp_predictor, hdp_type in zip(hdp_predictors_stage3, hdp_types):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Analyzing {hdp_type} pathway\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        if hdp_predictor not in df.columns:\n",
    "            print(f\"WARNING: {hdp_predictor} not found in data. Skipping.\")\n",
    "            all_results['clinical_utility'][hdp_predictor] = None\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            utility_results = clinical_predictive_utility_mixed(df, hdp_predictor, hdp_type)\n",
    "            all_results['clinical_utility'][hdp_predictor] = utility_results\n",
    "            if utility_results is not None:\n",
    "                all_p_values['clinical'][hdp_predictor] = utility_results['p_values']\n",
    "                                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error in clinical utility analysis for {hdp_type}: {e}\")\n",
    "            all_results['clinical_utility'][hdp_predictor] = None\n",
    "    \n",
    "    # ===== APPLY FDR CORRECTION =====\n",
    "    fdr_results = apply_fdr_correction(all_p_values)\n",
    "    \n",
    "    # ===== FINAL SUMMARY WITH BOTH RAW AND FDR P-VALUES =====\n",
    "    print(\"\\n\\n\" + \"=\"*80)\n",
    "    print(\"FINAL ANALYSIS SUMMARY\")\n",
    "    print(\"Reporting both raw and FDR-corrected p-values\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\n1. MEDIATION ANALYSIS RESULTS:\")\n",
    "    print(\"Format: Effect [95% CI] p-raw (p-FDR)\")\n",
    "    \n",
    "    for hdp_predictor, hdp_type in zip(hdp_predictors_stage1, hdp_types):\n",
    "        print(f\"\\n  {hdp_type} Pathway:\")\n",
    "        for beta_type in ['Total', 'Low', 'High']:\n",
    "            key = f'{hdp_predictor}_{beta_type}_Beta'\n",
    "            \n",
    "            # 3-month results\n",
    "            if key in all_results['mediation_3m']:\n",
    "                res = all_results['mediation_3m'][key]\n",
    "                acme = res['acme']['coeff']\n",
    "                ci = res['acme']['ci']\n",
    "                p_raw = res['acme']['pval']\n",
    "                p_fdr = fdr_results.get('mediation_fdr', {}).get(f\"{key}_3m_acme\", np.nan)\n",
    "                sig_raw = '*' if p_raw < 0.05 else ''\n",
    "                sig_fdr = '†' if p_fdr < 0.05 else ''\n",
    "                print(f\"    {beta_type} Beta (3m) ACME: {acme:.4f} [{ci[0]:.4f}, {ci[1]:.4f}] \"\n",
    "                      f\"p={p_raw:.4f}{sig_raw} (FDR={p_fdr:.4f}{sig_fdr})\")\n",
    "            \n",
    "            # 6-month results\n",
    "            if key in all_results['mediation_6m']:\n",
    "                res = all_results['mediation_6m'][key]\n",
    "                acme = res['acme']['coeff']\n",
    "                ci = res['acme']['ci']\n",
    "                p_raw = res['acme']['pval']\n",
    "                p_fdr = fdr_results.get('mediation_fdr', {}).get(f\"{key}_6m_acme\", np.nan)\n",
    "                sig_raw = '*' if p_raw < 0.05 else ''\n",
    "                sig_fdr = '†' if p_fdr < 0.05 else ''\n",
    "                print(f\"    {beta_type} Beta (6m) ACME: {acme:.4f} [{ci[0]:.4f}, {ci[1]:.4f}] \"\n",
    "                      f\"p={p_raw:.4f}{sig_raw} (FDR={p_fdr:.4f}{sig_fdr})\")\n",
    "    \n",
    "    print(\"\\n2. TEMPORAL COMPARISONS:\")\n",
    "    for key in all_results['temporal_comparisons']:\n",
    "        if all_results['temporal_comparisons'][key] is not None:\n",
    "            res = all_results['temporal_comparisons'][key]\n",
    "            diff = res['difference']\n",
    "            ci = res['ci']\n",
    "            p_raw = res['p_value']\n",
    "            p_fdr = fdr_results.get('temporal_fdr', {}).get(key, np.nan)\n",
    "            print(f\"  {key}: Δ={diff:.4f} [{ci[0]:.4f}, {ci[1]:.4f}] \"\n",
    "                  f\"p={p_raw:.4f} (FDR={p_fdr:.4f})\")\n",
    "    \n",
    "    print(\"\\n3. CLINICAL UTILITY (HDP Predictive Value):\")\n",
    "    for hdp_predictor, hdp_type in zip(hdp_predictors_stage3, hdp_types):\n",
    "        if all_results['clinical_utility'][hdp_predictor] is not None:\n",
    "            res = all_results['clinical_utility'][hdp_predictor]\n",
    "            z_stat = res['z_test']['z_stat']\n",
    "            p_raw = res['z_test']['p_value']\n",
    "            p_fdr = fdr_results.get('clinical_fdr', {}).get(f\"{hdp_predictor}_mixed\", np.nan)\n",
    "            \n",
    "            # MSE improvements\n",
    "            mse_pooled = res['mse_comparison']\n",
    "            improvement_pooled = (mse_pooled['pooled_model1'] - mse_pooled['pooled_model2']) / mse_pooled['pooled_model1'] * 100\n",
    "            improvement_3m = (mse_pooled['3_month_model1'] - mse_pooled['3_month_model2']) / mse_pooled['3_month_model1'] * 100 if not np.isnan(mse_pooled['3_month_model1']) else np.nan\n",
    "            improvement_6m = (mse_pooled['6_month_model1'] - mse_pooled['6_month_model2']) / mse_pooled['6_month_model1'] * 100 if not np.isnan(mse_pooled['6_month_model1']) else np.nan\n",
    "            \n",
    "            print(f\"  {hdp_type}: Z={z_stat:.3f}, p={p_raw:.4f} (FDR={p_fdr:.4f})\")\n",
    "            print(f\"    MSE improvement: Pooled={improvement_pooled:.1f}%, 3m={improvement_3m:.1f}%, 6m={improvement_6m:.1f}%\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANALYSIS COMPLETE\")\n",
    "    print(\"* = p < 0.05 (raw), † = p < 0.05 (FDR-corrected)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Save results\n",
    "    import pickle\n",
    "    with open('dbs_analysis_results_corrected.pkl', 'wb') as f:\n",
    "        pickle.dump({'results': all_results, 'fdr_correction': fdr_results}, f)\n",
    "    print(\"\\nResults saved to 'dbs_analysis_results_corrected.pkl'\")\n",
    "        \n",
    "    return all_results, fdr_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results, fdr_results = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
